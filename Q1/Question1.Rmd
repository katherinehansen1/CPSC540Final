---
title: "CPSC540 Final Project Question 1"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code.

## **Question**: Is there evidence that warned and non-warned pilots have the same mean birds hit? Does it even matter if they are warned?

-   I will investigate the relationship between warned and non-warned pilots, and if there's an impact on whether or not the warning plays a role in how many birds are hit.
-   To answer this question I will use the columns PilotWarned, a dummy variable to detect if a pilot was warned about birds in their flight path, and NumbersStruckActual, the count of birds hit by the plane. I will start by creating some visuals to complete exploratory data analysis on the distribution of birds hit in comparison to pilots warned. Once the domain is further understood, I plan on using both Bayesian and Frequentist processes to answer my hypothesis.
-   For the Bayesian portion, I will create a Bayesian regression model in R that measures the number of birds struck in regards to if the pilot is warned or not. I will look at the credible intervals (CI) to see if the difference in average birds struck is meaningful. That is, if the CI does not include zero. I would like to make some kind of visual of this to further convey this concept.
-   For the frequentist portion, I will follow the same kind of process, but instead use a generalized linear model in R that measures the same relationship. After fitting the model, I will utilize a two one-sided T-test (TOST), a form of equivalence testing to see if there is evidence that our null hypothesis is true, or if there is a statistically significant effect between the two types of pilots. I will complete TOST by using the tsum_TOST function.

```{r}
# Library City

library(ggdag)
library(dagitty)
library(ggplot2)
library(brms)
library(dplyr)
library(bayesplot)


getwd()
data <- read.csv('Bird_strikes.csv')
str(data)
data$Date <- as.Date(data$FlightDate, format = "%m/%d/%y %H:%M")
```

## Exploratory Data Analysis

```{r}
# Mean, Median, Quartiles, Maximum, Minimum
# maximum is quite outlierlina
summary(data$NumberStruckActual)

# Count of Instances - how many incidences were the pilots warned vs not warned about the birds in the sky?
table(data$PilotWarned)

data$WasWarned <- 0
data$WasWarned[data$PilotWarned == "Y"] <- 1

data

```

```{r}
# Visual which shows the count of birds hit by warned pilots vs not warned pilots
# just to give an idea and see if there's even a difference

str(data)

birds_hit <- data %>% group_by(PilotWarned) %>% summarise(NumberStruckCount = sum(NumberStruckActual), PilotCount = n())
birds_hit


ggplot(birds_hit, aes(x = PilotWarned, y = NumberStruckCount, fill = PilotWarned)) + 
  geom_bar(stat = "identity") +
  theme_minimal() + 
  theme(legend.position = "none") +
  geom_text(aes(label = NumberStruckCount, vjust = -0.3)) +
  labs(title = "Total Birds Hit by Warned vs. Un-Warned Pilots")
  
ggplot(birds_hit, aes(x = PilotWarned, y = PilotCount, fill = PilotWarned)) + 
  geom_bar(stat = "identity") +
  theme_minimal() + 
  theme(legend.position = "none") +
  geom_text(aes(label = PilotCount, vjust = -0.3)) +
  labs(title = "Count of Warned vs. Un-Warned Pilots")

```

```{r}
# warnings over time
data

max_data <- data %>%
  filter(NumberStruckActual == max(NumberStruckActual))

ggplot(data, aes(x = Date, y = NumberStruckActual, color = PilotWarned)) + 
  geom_bar(stat = "identity", show.legend = FALSE) + 
  facet_wrap(~PilotWarned) + 
  geom_text(data = max_data,aes(label = NumberStruckActual), vjust = -0.5, size = 3) + theme_minimal()
```

```{r}
# Box plot of the column
boxplot(data$NumberStruckActual, 
        main = "Instances of Birds Struck Counts", # oooo name that better
        xlab = "Birds Struck", 
        ylab = "Values", 
        col = "lightblue", 
        horizontal = TRUE)  # Use horizontal = TRUE for horizontal orientation

```

## Bayesian Process

#### Gonna go back and watch her video to clean up what I have done. I am getting to a point where I'm over it, just trying to put a pen to paper yk

```{r}
# Bayesian Hypothesis Testing


# Prior Selection. Here's attempt 1 with what I saw in the lecture video

# Keep updating this to make a more realistic prior...i feel it's getting too uninformative and that i am pissing in the dark with this
priors <- c(
  prior("normal(0, 5)", class = "b"), # wider effect for coefficient
  prior("normal(0, 4)", class = "Intercept"), # mean of 2? maybe this makes things closer to reality...
  prior("gamma(0.1, 10)", class = "sigma") # substantial spread in variance
  # should I just focus on coefficient?
)

# Prior Distribution Check....ugh it's fugly
mod_0 <- brm(NumberStruckActual ~ WasWarned, data = data, prior = priors, sample_prior = "only")
mod_0 |> pp_check() + xlim(-15, 15)
```

```{r}
# Attempt 2

# Less Informed Priors? Going to see how the model defaults without any established priors. Good place to start I guess

# Lower bound idea: https://discourse.mc-stan.org/t/checking-understanding-of-bounds-on-priors/8940 since we at least need a collision value of 1. Stop predicting negatives!

# Log normal idea to introduce non-negativity.

# took out variance

# dunno how to tame the coeff...lock in on this later ig.

priors <- c(prior("normal(0, 2)", class = "b", lb = 0),
            prior("lognormal(log(2.7), 0.5)", class = "Intercept"))
            #prior("gamma(2, 0.5)", class = "sigma", lb = 0))

mod_1 <- brm(NumberStruckActual ~ WasWarned, data = data, prior = priors, sample_prior = "only")

get_prior(mod_1)

mod_1 |> pp_check()
mod_1 |> pp_check() + xlim(-15, 15)
```

```{r}
# Measure convergence & metrics
mcmc_trace(mod_1)

```

```{r}
# Posterior Distribution Check 
# poisson likelihood function for non-negativity count (count of birds hit)
mod_1 <- brm(NumberStruckActual ~ WasWarned, data = data, prior = priors, family = poisson())

mod_1 |> pp_check() + xlim(-50, 50)
summary(mod_1)

```

```{r}
mod_1$fit

# Posterior Examination - parameter estimation for the coefficient
# plot a parameter for coefficient to see densitiy of posteriors for each values
# red plots that show our region of practical equivalence
# all of the posterior is outside of the rope

mcmc_areas(mod_1, pars = c("b_WasWarned"))
```

## Frequentist Process

```{r}
# Modeling Modeling

# poisson for count
mod_2 <- glm(NumberStruckActual ~ WasWarned, data = data, family = poisson())

summary(mod_2)
confint(mod_2)

```

-   Equivalence Testing last thing i will fix before presentation and then this is what i will roll with for now.

```{r}
# T-testing
data$Warned <- 0
data$Warned[data$PilotWarned == "Y"] <- 1

data$NotWarned <- 0
data$NotWarned[data$PilotWarned == "N"] <- 1

# is the difference in mean birds hit different than 0? is there an effect?

t.test(x = data$NumberStruckActual[data$Warned == 1],
       y = data$NumberStruckActual[data$NotWarned == 1],
       alternative = "two.sided")
```

```{r}
library(TOSTER)

# Inspo came from HW2. I'll adjust it accordingly.

coef_summary <- summary(mod_2)$coefficients
coef_summary

mean_diff <- coef_summary["PilotWarnedY", "Estimate"]
std_error <- coef_summary["PilotWarnedY", "Std. Error"]

# Use the PilotWarnedY coefficient from GLM
TOST_result <- tsum_TOST(
  m1 = mean_diff,
  mu = 0,
  sd1 = std_error, 
  n1 = nrow(dat), 
  low_eqbound = -0.1*std_error, 
  high_eqbound = 0.1*std_error
)

# Ask about better ways to do TOST because I am not quite confident here

TOST_result$decision

# visual?
```

-   x\^2 Test. this is kinda bad

    ```{r}
    # Clean data to where theres a dummy var for if the pilot is warned, if the pilot is not warned


    # Measure the independence of warnings and birds being hit

    hit <- data %>%
      group_by(WasWarned) %>%
      summarise(BirdsHit = sum(NumberStruckActual))

    chisq_test <- chisq.test(hit$BirdsHit)
    print(chisq_test)
    ```
